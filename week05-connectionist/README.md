# Neural Network Foundations

## Objectives
- Understand perceptrons, activation functions, and backpropagation.
- Learn about the universal approximation theorem.
- Implement neural networks from scratch.

## Readings
- *Deep Learning* – Ian Goodfellow et al., Chapters 6 and 7.
- *Neural Networks and Deep Learning* – Michael Nielsen (free online).
- "The Perceptron: A Probabilistic Model" – Rosenblatt (1958).

## Practice
- Build a perceptron and train it on a simple classification task.
- Implement backpropagation using NumPy.
- Visualize activation functions (sigmoid, tanh, ReLU).

## Notes
- Reflect on the strengths and limitations of single-layer perceptrons.
- Write about how gradient descent affects learning.
